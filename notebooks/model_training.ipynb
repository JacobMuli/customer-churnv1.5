{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OKc6vaB-lMgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9798c6db-4a46-469e-8ddb-85098dedced6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 249999, number of negative: 249999\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063043 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2571\n",
            "[LightGBM] [Info] Number of data points in the train set: 499998, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Model training complete. All artifacts saved.\n"
          ]
        }
      ],
      "source": [
        "# 04. Model Training (FINAL FIXED VERSION)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "\n",
        "# -----------------------------\n",
        "# LOAD PREPROCESSED DATA\n",
        "# -----------------------------\n",
        "train = pd.read_csv(\"train_processed.csv\")\n",
        "\n",
        "# FULL FEATURE SET\n",
        "X = train.drop(\"Churn\", axis=1)\n",
        "y = train[\"Churn\"]\n",
        "\n",
        "# Identify object columns (should be NONE after preprocessing)\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# If there are still categorical columns â†’ encode them\n",
        "label_encoders = {}\n",
        "X_encoded = X.copy()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# -----------------------------\n",
        "# SCALE NUMERIC FEATURES\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_encoded)\n",
        "\n",
        "# -----------------------------\n",
        "# BALANCE THE DATA\n",
        "# -----------------------------\n",
        "sm = SMOTE(random_state=42)\n",
        "X_bal, y_bal = sm.fit_resample(X_scaled, y)\n",
        "\n",
        "# -----------------------------\n",
        "# TRAIN MODEL\n",
        "# -----------------------------\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=600,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=-1,\n",
        "    num_leaves=50,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgb_model.fit(X_bal, y_bal)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# SAVE EVERYTHING FOR INFERENCE\n",
        "# -----------------------------\n",
        "\n",
        "# Save model\n",
        "joblib.dump(lgb_model, \"rf_model.pkl\")\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "# Save label encoders (if any)\n",
        "joblib.dump(label_encoders, \"label_encoders.pkl\")\n",
        "\n",
        "# Save the column order used during training\n",
        "joblib.dump(list(X_encoded.columns), \"feature_names.pkl\")\n",
        "\n",
        "print(\"Model training complete. All artifacts saved.\")"
      ]
    }
  ]
}