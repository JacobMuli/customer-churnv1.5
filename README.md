# ğŸ“Š Customer Churn Prediction â€“ Streamlit App V1.5

This repository contains a **Streamlit web application** for predicting customer churn using a **Random Forest model** trained on engineered customer behavioral, demographic, and interaction features.

The project includes:
- A full ML pipeline (preprocessing â†’ feature engineering â†’ training â†’ evaluation â†’ inference)
- A deployed-ready Streamlit application
- Saved model artifacts for inference
- Modularized notebooks for transparency and reproducibility

---

## ğŸš€ Demo

The app predicts whether a customer is **likely to churn or stay**, based on input features such as:
- Age
- Gender
- Tenure
- Subscription Type
- Contract Length
- Usage Frequency
- Support Calls
- Payment Behavior  
â€¦and several engineered features.

---

## ğŸ“ Repository Structure

customer-churn/
â”‚
â”œâ”€â”€ app.py # Streamlit application
â”œâ”€â”€ requirements.txt # Package dependencies
â”œâ”€â”€ .gitignore # Files ignored in GitHub
â”‚
â”œâ”€â”€ model/ # Model artifacts (safe for repo)
â”‚ â”œâ”€â”€ rf_model.pkl
â”‚ â”œâ”€â”€ scaler.pkl
â”‚ â”œâ”€â”€ label_encoders.pkl
â”‚ â”œâ”€â”€ feature_names.pkl
â”‚
â”œâ”€â”€ notebooks/ # Jupyter Notebooks (NOT needed for deployment)
â”‚ â”œâ”€â”€ 01_data_load_and_basic_eda.ipynb
â”‚ â”œâ”€â”€ 02_eda_analysis.ipynb
â”‚ â”œâ”€â”€ 03_data_preprocessing_and_feature_engineering.ipynb
â”‚ â”œâ”€â”€ 04_model_training.ipynb
â”‚ â”œâ”€â”€ 05_model_evaluation.ipynb
â”‚ â”œâ”€â”€ 06_model_export_and_inference.ipynb
â”‚
â”œâ”€â”€ data/ # Example input data (DO NOT upload large CSVs)
â”‚ â”œâ”€â”€ sample_input.json
â”‚
â””â”€â”€ README.md


---

## ğŸ§  Machine Learning Workflow

### **1. Data Preprocessing**
- Missing value handling  
- Dropping unused identifiers  
- Encoding categorical features  
- One-hot encoding of subscription & contract types  
- Feature engineering:
  - Average Monthly Spend  
  - Support Intensity  
  - Recency/Tenure Ratio  
  - Age Group segmentation  

### **2. Balancing**
SMOTE is used to handle class imbalance.

### **3. Scaling**
`StandardScaler` is applied to numeric fields.

### **4. Model**
The chosen model is:
- **Random Forest Classifier**  
  - Tuned hyperparameters  
  - Balanced class weighting  

### **5. Saved Artifacts**
The following files support inference:

rf_model.pkl # The trained model
scaler.pkl # Feature scaler
label_encoders.pkl # Encoders (if any)
feature_names.pkl # Ordered list of columns used during training


---

## ğŸ–¥ Running the App Locally

### **1. Install dependencies**
pip install -r requirements.txt


### **2. Run Streamlit**
streamlit run app.py


### **3. Open browser**
[
](http://localhost:8501)

---

## â˜ï¸ Deploy to Streamlit Cloud (Recommended)

1. Push this repository to **GitHub**  
2. Go to: https://share.streamlit.io  
3. Click **Deploy an app**  
4. Select your repo  
5. Set **Main file** â†’ `app.py`  
6. Deploy ğŸ‰  

Streamlit Cloud will:
- Install dependencies from `requirements.txt`
- Load model artifacts from `/model`
- Launch the app automatically

---

## ğŸ“ˆ Inputs and Prediction Output

### Input fields include:
- Age  
- Gender  
- Tenure  
- Usage Frequency  
- Support Calls  
- Payment Delay  
- Total Spend  
- Last Interaction  
- Subscription Type  
- Contract Length  

### The model returns:
- **Churn Probability** (0.00 â€“ 1.00)  
- **Final Prediction** (Likely to churn / Not likely to churn)

---

## ğŸ›¡ Notes & Best Practices

- Training datasets (**train.csv**, **train_processed.csv**) are intentionally **NOT included** in the repo due to size limits and privacy.
- Do **NOT** upload large CSV files to GitHub.
- The app uses only `.pkl` model artifacts.

---

## ğŸ§© Future Enhancements

- Add SHAP explainability  
- Add batch prediction via CSV upload  
- Add authentication  
- Convert pipeline into a single `sklearn.Pipeline` object  
- Deploy using Docker or HuggingFace Spaces  

---

## ğŸ‘¨â€ğŸ’» Author

This project was auto-generated and improved by **ChatGPT AI** based on user specifications.

---

## â­ Support

If you like this project, please â­ star the repository on GitHub!

